1
00:00:00,730 --> 00:00:03,600
我将要描述一下爬取过程 并把它写出来

2
00:00:03,600 --> 00:00:07,740
用一种比较准确的方法 但不是真正的 python 代码

3
00:00:07,740 --> 00:00:10,500
因为完成它的 python 代码是你的任务

4
00:00:10,500 --> 00:00:13,460
但是我想在这先尽可能准确地描述它一下 这样才能

5
00:00:13,460 --> 00:00:16,820
问些关于它的问题 我们将从一些种子页面开始

6
00:00:16,820 --> 00:00:19,970
然后 tocrawl 就是这些页面 这个列表中包含了种子页面

7
00:00:19,970 --> 00:00:23,530
而 crawed 则是空的 之后我们不停的爬取

8
00:00:23,530 --> 00:00:26,040
只要还有可以爬取的页面 关于每一步

9
00:00:26,040 --> 00:00:29,200
我们将选出一个页面 然后把它加入

10
00:00:29,200 --> 00:00:31,610
crawled 里 来记下我们已经爬取过它了

11
00:00:31,610 --> 00:00:35,030
之后我们将找出在这个页面上的所有链接

12
00:00:35,030 --> 00:00:38,880
把它们加进 tocrawl 之后继续

13
00:00:38,880 --> 00:00:41,480
只要 tocrawl 里面还有页面

14
00:00:41,480 --> 00:00:45,110
最后完成时 我们将返回 crawled

15
00:00:45,110 --> 00:00:48,630
这就是最基本的爬取过程了 在小测试中

16
00:00:48,630 --> 00:00:51,290
我希望能看到你理解了这个爬取网页的过程

17
00:00:51,290 --> 00:00:54,500
并且足够去理解将会发生什么

18
00:00:54,500 --> 00:00:57,580
如果我们从测试网页的种子页面开始爬取的话

19
00:00:57,580 --> 00:01:01,730
你也可以试着自己来探索一下这些网页

20
00:01:01,730 --> 00:01:04,019
问题的选项是 将返回一个列表

21
00:01:04,019 --> 00:01:06,900
包含了所有从种子页面可以得到的 URL

22
00:01:08,320 --> 00:01:10,430
第二个选项是 将返回一个列表

23
00:01:10,430 --> 00:01:12,990
只包含一些而不是所有的从种子页面可以得到的 URL

24
00:01:12,990 --> 00:01:16,860
第三个选项是 将永远不返回
