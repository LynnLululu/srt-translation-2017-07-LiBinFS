1
00:00:00,000 --> 00:00:02,000
这里我已经构建了一个虚拟的互联网

2
00:00:02,000 --> 00:00:06,000
它比真正的互联网小了很多

3
00:00:06,000 --> 00:00:11,000
但是它是一个非常好的用来展示我们想要如何修改爬虫来解决最大页数问题的互联网实例

4
00:00:11,000 --> 00:00:14,000
这个问题要求我们在获取到一定数量的页面之后

5
00:00:14,000 --> 00:00:18,000
阻止爬虫继续搜索因特网

6
00:00:18,000 --> 00:00:24,000
如果是真实的互联网 链接会多得多. 本质上链接可以几乎永远跳转下去

7
00:00:24,000 --> 00:00:27,000
互联网上有数以亿计的网页  

8
00:00:27,000 --> 00:00:30,000
如果我们使用本单元写的代码

9
00:00:30,000 --> 00:00:35,000
那么搜索时间将会很长很长

10
00:00:35,000 --> 00:00:38,000
我让你自行估算它将会花费多长的时间

11
00:00:38,000 --> 00:00:41,000
这个时间甚至大于本课程的所有时长

12
00:00:41,000 --> 00:00:44,000
实际上我们要做的是

13
00:00:44,000 --> 00:00:48,000
当网页爬虫抓取到一定数量的页面后让它停止工作

14
00:00:48,000 --> 00:00:51,000
如果我们只是记录通过遍历我们的因特网实例而发现的页面总数

15
00:00:51,000 --> 00:00:54,000
并且只是将它和传入的最大网页数作比较的话

16
00:00:54,000 --> 00:00:58,000
这是非常容易做到的

17
00:00:58,000 --> 00:01:05,000
我们假设最大页面数等于3 网页爬虫将要做的是从 A 开始抓取

18
00:01:05,000 --> 00:01:10,000
由A开始 我们抓取 A 得到 B 和 C

19
00:01:10,000 --> 00:01:13,000
接着我们搜索 C 得到 D 和 E

20
00:01:13,000 --> 00:01:17,000
但是我们现在已经搜索了3个页面 所以我们想要结束这个过程

21
00:01:17,000 --> 00:01:23,000
为了实现上述过程 让我们来研究一下我们在本单元结束时写的代码并修改它

22
00:01:23,000 --> 00:01:25,000
这是我们的网页搜索函数

23
00:01:25,000 --> 00:01:28,000
我们传入一个参数-最大页数

24
00:01:28,000 --> 00:01:32,000
一旦抓取的页面数等于这个值 我们就停止搜索

25
00:01:32,000 --> 00:01:37,000
一个简单的核对方法只是查看爬取列表的长度 

26
00:01:37,000 --> 00:01:40,000
使用 len 操作符就可获得这个值

27
00:01:40,000 --> 00:01:43,000
我们不仅希望抓取未被搜索的网页

28
00:01:43,000 --> 00:01:46,000
而且还希望只在已获取的网页列表的长度小于最大页数的时候抓取
