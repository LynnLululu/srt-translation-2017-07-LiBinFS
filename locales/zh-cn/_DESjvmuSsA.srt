1
00:00:00,480 --> 00:00:04,500
答案是它永远不会返回

2
00:00:04,500 --> 00:00:07,000
原因是这里 while 循环的继续条件是

3
00:00:07,000 --> 00:00:10,160
还有更多的页面去爬取

4
00:00:10,160 --> 00:00:13,255
因此我们不停地进行这一步只要

5
00:00:13,255 --> 00:00:15,920
还有页面在 tocrawl 中 所以为了结束循环

6
00:00:15,920 --> 00:00:18,800
需要知道 tocrawl 的值最后确实变成了空值

7
00:00:18,800 --> 00:00:22,050
但是当我们来查看测试网站时

8
00:00:22,050 --> 00:00:25,830
如果你跟随 walking 链接 这也是爬虫会做的

9
00:00:25,830 --> 00:00:28,165
你将会到达这个页面 有一个到 crawling 的链接

10
00:00:28,165 --> 00:00:31,850
这样我们又回到了目录页面

11
00:00:31,850 --> 00:00:35,290
这将会不断进行下去 你将再次跟随 walking 链接

12
00:00:35,290 --> 00:00:38,210
然后跟随 crawling 链接 walking 链接 再继续 crawling 链接

13
00:00:38,210 --> 00:00:41,340
回到目录 这将会永远继续下去

14
00:00:41,340 --> 00:00:45,900
爬虫永远都不会停下来 因为它将总能找到一个链接来爬取

15
00:00:45,900 --> 00:00:48,570
而且真实的网页上充满了

16
00:00:48,570 --> 00:00:51,010
像这样的循环链接 有很多页面会

17
00:00:51,010 --> 00:00:53,180
互相链接 也有些网页甚至会链接回它自己

18
00:00:53,180 --> 00:00:56,340
为了避免这个 我们需要做一下更巧妙的处理

19
00:00:56,340 --> 00:00:59,880
确定我们不会去爬取已经爬取过的页面

20
00:00:59,880 --> 00:01:02,690
因此要对这一步进行一些

21
00:01:02,690 --> 00:01:05,890
更小心的处理 我们需要加一个测试

22
00:01:05,890 --> 00:01:10,210
来看看是否以及爬过这个页面了 如果已经爬过了

23
00:01:10,210 --> 00:01:13,380
就什么都不干 如果没有 那么

24
00:01:13,380 --> 00:01:16,130
我们需要把它加入 tocrawl 中去 把所有在这个页面上的链接

25
00:01:16,130 --> 00:01:17,540
加入到 tocrawl 中去 然后继续
