1
00:00:00,380 --> 00:00:03,150
祝贺你 现在你已经搭建了一个网络爬虫 并能用它来爬取

2
00:00:03,150 --> 00:00:06,590
虽不能说进展神速 但是

3
00:00:06,590 --> 00:00:09,960
对于仅仅三个单元 你已经学到很多了

4
00:00:09,960 --> 00:00:13,560
通过学习列表(list) 你可以用它搭建任何其他想要的数据结构

5
00:00:13,560 --> 00:00:16,350
在下一个单元中 还有之后的单元

6
00:00:16,350 --> 00:00:18,660
我们会看到很多其他的东西

7
00:00:18,660 --> 00:00:22,400
都会使用到列表 其实我们还没有真正完成一个搜索引擎

8
00:00:22,400 --> 00:00:25,410
但是我们已经有了一个好的开始了

9
00:00:25,410 --> 00:00:28,630
我们找到所有要爬取的页面了

10
00:00:28,630 --> 00:00:31,120
而第四单元是 通过从种子页面开始

11
00:00:31,120 --> 00:00:35,232
然后用我们写的爬取网页的程序获得网页

12
00:00:35,232 --> 00:00:38,640
之后如何来从这些页面获得内容 再用这些来建立一个目录

13
00:00:38,640 --> 00:00:41,280
这样我们才能 当某人搜索一个关键词时

14
00:00:41,280 --> 00:00:44,480
能对他的查询指令做出回应 此外

15
00:00:44,480 --> 00:00:47,320
在第四单元 我们还会学到因特网和网络是如何工作的

16
00:00:47,320 --> 00:00:50,450
现在和我站在一起的是 Anna Patterson

17
00:00:50,450 --> 00:00:52,270
她搭建过很多搜索引擎 其中包括

18
00:00:52,270 --> 00:00:53,940
建立世界上最大的网络目录 现在

19
00:00:53,940 --> 00:00:58,200
她在给谷歌工作 因为我们刚刚完成一个非常简单的网络爬虫

20
00:00:58,200 --> 00:01:00,810
所以我想让 Anna 来告诉我们 当你想建立

21
00:01:00,810 --> 00:01:03,534
一个谷歌处理规模的爬虫时 会有哪些不同

22
00:01:04,940 --> 00:01:08,080
—— 当你想扩大网络爬虫规模时 这里主要有

23
00:01:08,080 --> 00:01:10,470
三个问题 第一是关于你在网络上需要的

24
00:01:10,470 --> 00:01:12,890
正常礼仪 第二个问题是

25
00:01:12,890 --> 00:01:15,810
如何用很多台计算机来同时进行爬取

26
00:01:15,810 --> 00:01:21,710
不仅仅只是一台 最后一个问题是如何充分用掉大量带宽

27
00:01:21,710 --> 00:01:24,700
这样才不会让这个昂贵的资源被浪费掉 但同时

28
00:01:24,700 --> 00:01:28,500
又要注意礼貌 首先关于礼貌的问题

29
00:01:28,500 --> 00:01:32,220
在每个域名的 robots.txt 中 都会有一行告诉你

30
00:01:32,220 --> 00:01:34,990
多久你能对这个域名爬取一次

31
00:01:34,990 --> 00:01:37,480
但是这里还有很多问题 首先

32
00:01:37,480 --> 00:01:41,360
多个域名可以由一个托管服务来托管

33
00:01:41,360 --> 00:01:43,850
有时甚至会由一台服务器来托管

34
00:01:43,850 --> 00:01:46,920
所以即使你对单个域名很文雅礼貌

35
00:01:46,920 --> 00:01:50,470
但还是会对一个托管服务 或者服务器造成伤害

36
00:01:50,470 --> 00:01:54,300
所以你得制定计划来爬取

37
00:01:54,300 --> 00:01:56,560
这样才不会对一个服务器或者域名造成太大负担

38
00:01:56,560 --> 00:02:00,180
下一个问题是 如果你只用一台计算机来爬取

39
00:02:00,180 --> 00:02:03,990
那么爬虫的状态会非常好 并且

40
00:02:03,990 --> 00:02:07,160
在一台计算机上 可以非常容易

41
00:02:07,160 --> 00:02:09,080
记录爬取状态 但是因为你最多只能

42
00:02:09,080 --> 00:02:12,030
用一台计算机来爬取 所以

43
00:02:12,030 --> 00:02:14,790
很难做一个非常大的搜索引擎 在实际情况

44
00:02:14,790 --> 00:02:18,950
会用成千上万的计算机来爬取 现在

45
00:02:18,950 --> 00:02:21,720
如果你要继续遵守礼貌 那就意味着

46
00:02:21,720 --> 00:02:25,610
你的这些计算机每台都得互相告诉对方

47
00:02:25,610 --> 00:02:28,650
什么已经爬取了 什么将要去爬取

48
00:02:28,650 --> 00:02:32,260
什么将要在20分钟后去爬取 对吗？

49
00:02:32,260 --> 00:02:36,460
所有的这些交流开销都会减慢爬虫的速度

50
00:02:36,460 --> 00:02:38,100
这对你搭建一个大型搜索引擎

51
00:02:38,100 --> 00:02:42,190
非常不利 最后一个问题是
52
00:02:42,190 --> 00:02:45,250
如何充分利用好你的带宽 所以人们会

53
00:02:45,250 --> 00:02:48,390
先对已经有的语料库进行预处理

54
00:02:48,390 --> 00:02:52,690
而不是来尽量减少通信

55
00:02:52,690 --> 00:02:54,750
因此当你爬取了一组页面

56
00:02:54,750 --> 00:02:57,600
你可以处理它们 并且抽出

57
00:02:57,600 --> 00:03:02,900
所有它们指向的链接 你之后标准化这些链接

58
00:03:02,900 --> 00:03:07,060
这样 Yahoo.com 或者 什么什么.yahoo.com 会以同样字符串结束

59
00:03:07,060 --> 00:03:09,700
之后你就可以移交这些

60
00:03:09,700 --> 00:03:12,660
字符串给你的上千台电脑了

61
00:03:12,660 --> 00:03:15,940
这样它们就不需要互相交流了

62
00:03:15,940 --> 00:03:19,800
因为它们知道它们不会爬取到同样的域名

63
00:03:19,800 --> 00:03:22,790
然而 它们可能也会偶然访问到

64
00:03:22,790 --> 00:03:25,790
同一个托管服务或者服务器 但是你可以

65
00:03:25,790 --> 00:03:27,420
提前设定好来避免这个的发生

66
00:03:27,420 --> 00:03:31,130
—— 谢谢 Anna 我希望你们中想把网络爬虫

67
00:03:31,130 --> 00:03:32,690
放到网上爬取的人

68
00:03:32,690 --> 00:03:34,680
注意一下她说的关于礼貌的问题

69
00:03:34,680 --> 00:03:37,859
—— 谢谢你邀请我 同时谢谢同学们 祝你们一切顺利

70
00:03:39,060 --> 00:03:40,020
—— 我希望能看到你很快回来继续学习

71
00:03:40,020 --> 00:03:41,860
将会有第三单元的作业等着你

72
00:03:41,860 --> 00:03:44,160
它非常有挑战性 同时我希望

73
00:03:44,160 --> 00:03:45,930
能看到你对它所有的解答
